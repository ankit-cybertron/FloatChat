# ARGO Ocean Data Discovery & Visualization

<p align="center">
  <img src="ARGO Ocean Data Discovery & Visualization/output/images/Screenshot 2026-01-14 at 1.29.48â€¯AM.png" width="800" alt="ARGO Data Visualization Demo">
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.11+-blue.svg" alt="Python">
  <img src="https://img.shields.io/badge/Dash-2.17.x-orange.svg" alt="Dash">
  <img src="https://img.shields.io/badge/FastAPI-0.114.x-green.svg" alt="FastAPI">
  <img src="https://img.shields.io/badge/SQLite-Integrated-blue.svg" alt="SQLite">
  <img src="https://img.shields.io/badge/Plotly-5.24.x-purple.svg" alt="Plotly">
</p>

A comprehensive platform for discovering, processing, and analyzing ARGO ocean float data. This project combines a **high-performance Indian Ocean data system**, an **interactive research dashboard**, and **FloatChat**â€”an AI-powered conversational interface for natural language data querying.

---

## ğŸ“– About

The ARGO Ocean Data Discovery & Visualization platform is designed to make vast amounts of oceanographic data accessible and actionable. It specifically targets the **Indian Ocean region**, providing specialized tools to filter, store, and visualize float data with sub-second latency.

### System Architecture

```mermaid
flowchart LR
  subgraph Client
    Dash[Dash Frontend]
  end
  subgraph Backend
    API[FastAPI RAG Service] -- & SQL --> DB[(SQLite/PG)]
    API -- Embeddings --> Chroma[(Chroma Vector DB)]
  end
  Dash -- HTTP --> API
  Dash -- Direct Read --> DB
```

### How It Works

1.  **Data Ingestion**: Processes raw global ARGO CSV data.
2.  **Geographic Filtering**: Automatically extracts floats within the Indian Ocean boundaries (20Â°E-120Â°E, 40Â°S-25Â°N).
3.  **Intelligent Processing**: Handles missing data with realistic filler generation based on regional parameters.
4.  **Storage**: Stores processed profiles in an optimized SQLite database for fast access.
5.  **Visualization**:
    *   **Dashboard**: Interactive maps and profile viewers options.
    *   **RAG AI**: Natural language queries converted to SQL or visualizations.

---

## ğŸ“ Project Structure

ARGO Ocean Data Discovery & Visualization/
â”‚
â”œâ”€â”€ backend/                        # FastAPI RAG backend
â”‚   â””â”€â”€ rag_service.py              # Main API service
â”œâ”€â”€ dash_frontend/                  # Frontend applications
â”‚   â”œâ”€â”€ research_dashboard.py       # Main interactive dashboard
â”‚   â”œâ”€â”€ simple_app.py               # Legacy/Simple interface
â”‚   â””â”€â”€ assets/                     # CSS and static assets
â”‚
â”œâ”€â”€ data/                           # Data storage
â”‚   â””â”€â”€ indian_ocean_floats.db      # Optimized SQLite database
â”‚
â”œâ”€â”€ src/                            # Core Python modules
â”‚   â”œâ”€â”€ data_processor.py           # Core processing & filtering logic
â”‚   â”œâ”€â”€ dashboard_data_integration.py # Bridge between DB and Dashboard
â”‚   â””â”€â”€ argo_float_rag.py           # RAG/LLM implementation
â”‚
â”œâ”€â”€ scripts/                        # Utility and setup scripts
â”‚   â”œâ”€â”€ setup_indian_ocean_data.py  # Database initialization script
â”‚   â””â”€â”€ ingest.py                   # Data ingestion utilities
â”‚
â”œâ”€â”€ output/                         # Generated assets (plots, reports)
â”œâ”€â”€ docs/                           # Documentation
â”œâ”€â”€ requirements.txt                # Project dependencies
â”œâ”€â”€ Dockerfile                      # Container configuration
â””â”€â”€ README.md                       # This file
```

### Core Components

#### Data System (`src/data_processor.py`)
- **`IndianOceanArgoProcessor`**: Filters global data and creates the regional database.
- **`IndianOceanDataAccess`**: Provides optimized query methods (spatial, temporal, parametric).

#### Dashboard (`dash_frontend/`)
- **`research_dashboard.py`**: The primary UI for researchers, featuring map views, profile analysis, and regional filtering.

#### AI Assistant (`backend/` & `src/argo_float_rag.py`)
- **FloatChat**: A RAG-based assistant that allows users to ask questions like "Show me floats near Madagascar" and receive generated SQL or plots.

---

## âœ¨ Features

- âœ… **Indian Ocean Focus**: Specialized filtering for the Indian Ocean region.
- âœ… **High-Performance DB**: SQLite implementation with spatial indexing for sub-second queries.
- âœ… **Interactive Map**: Real-time float tracking with `scattergeo`/`mapbox`.
- âœ… **Profile Viewer**: Detail views for Temperature, Salinity, and Pressure profiles.
- âœ… **AI-Powered Chat**: Natural Language to SQL/Visualization using RAG.
- âœ… **Data Quality Control**: Automated validation and realistic filler for missing values.
- âœ… **Responsive Design**: Modern dashboard UI built with Dash.
- âœ… **Export Capabilities**: Export data to CSV, NetCDF, or GeoJSON.

---

## ğŸ›  Requirements

### Python Version
- Python 3.11 or higher

### Key Libraries
```bash
dash                # Web framework
plotly              # Interactive plotting
pandas              # Data manipulation
fastapi             # Backend API
chromadb            # Vector database for RAG
sentence-transformers # Text embeddings
geopandas           # Spatial data handling
sqlalchemy          # Database ORM
```

---

## ğŸš€ Installation

### Step 1: Clone the Repository
```bash
git clone <repository-url>
cd "ARGO Ocean Data Discovery & Visualization"
```

### Step 2: Set Up Environment
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### Step 3: Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 4: Initialize Data
Run the setup script to process the data and create the local database.
```bash
python scripts/setup_indian_ocean_data.py
```
*Note: This will look for ARGO CSV data. You can specify a custom path using `--csv-path`.*

---

## ğŸ’» Usage

### 1. Research Dashboard (Recommended)
The main interface for data exploration.
```bash
python dash_frontend/research_dashboard.py
```
> **Access at**: `http://localhost:8050`

### 2. FloatChat (AI Assistant)
To run the full RAG system:

**Terminal 1 (Backend):**
```bash
uvicorn backend.rag_service:app --reload
```

**Terminal 2 (Frontend):**
```bash
BACKEND_URL=http://localhost:8000 python dash_frontend/simple_app.py
```

---

## âš™ï¸ Configuration

### Database Settings
The system defaults to using a local SQLite database in `data/indian_ocean_floats.db`. You can customize this in `dashboard_data_integration.py`.

### Environment Variables
Create a `.env` file for advanced configuration:
```env
DATABASE_URL=sqlite:///data/indian_ocean_floats.db
AUTH_TOKEN=your-dev-token
MAPBOX_TOKEN=your-mapbox-token-optional
```

---

## ğŸ§  Technical Details

### Database Schema
The core `profiles` table is optimized for scientific queries:

```sql
CREATE TABLE profiles (
    id INTEGER PRIMARY KEY,
    float_id TEXT,
    datetime TEXT,
    latitude REAL,
    longitude REAL,
    depth REAL,
    temperature REAL,
    salinity REAL,
    -- ... indexes on lat/lon, time
);
```

### RAG Pipeline
1.  **Query Analysis**: Determines if the user is asking for SQL data, general info, or a plot.
2.  **Retrieval**: Fetches relevant schema info and summary stats from ChromaDB.
3.  **Generation**: LLM constructs the SQL query or Plotly specification.
4.  **Execution**: Runs the query against the database and returns results.

---

## ğŸ”§ Troubleshooting

### Database Not Found
```
Error: Database file not found at ...
```
**Solution**: Run `python setup_indian_ocean_data.py` to generate the database first.

### Missing Dependencies (GeoPandas)
If you encounter errors installing `geopandas` or `shapely`, ensure you have system libraries installed (e.g., `libgeos-dev` on Linux).

### Port Conflicts
If port 8050 or 8000 is in use, you can specify a distinct port in the run commands:
```bash
python dash_frontend/research_dashboard.py --port 8051
```

---

## ğŸ“ˆ Future Improvements

- [ ] Selectable date ranges for animations
- [ ] Integration of live ARGO API feed
- [ ] 3D visualization of ocean profiles
- [ ] Comparison tool for multi-float analysis
- [ ] Advanced anomaly detection models

---

## ğŸ“š References

- **Argo Program**: [https://argo.ucsd.edu](https://argo.ucsd.edu)
- **Dash Documentation**: [https://dash.plotly.com](https://dash.plotly.com)
- **FastAPI**: [https://fastapi.tiangolo.com](https://fastapi.tiangolo.com)

---

## ğŸ“„ License

This project is available under the MIT License.

---

## âš ï¸ Disclaimer

This tool is for research and educational purposes. Data fillers used for missing values are statistically generated for testing and should be verified against official sources for publication.
